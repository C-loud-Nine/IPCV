# =============================================================================
# COMPREHENSIVE MOTION DEBLURRING PIPELINE
# =============================================================================
# This pipeline performs robust motion deblurring using a multi-stage approach:
# 1. Adaptive denoising (BM3D + wavelet fallback)
# 2. Robust PSF estimation (Radon transform + cepstrum analysis)
# 3. Wiener deconvolution with adaptive regularization
# 4. Multiscale Richardson-Lucy with TV regularization
# 5. Adaptive sharpening and contrast enhancement
# =============================================================================

# =============================================================================
# Cell 1: Essential Imports and Configuration
# =============================================================================

import os
import math
import random
import time
import warnings
import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy import ndimage
from scipy.signal import fftconvolve, find_peaks
from skimage import img_as_float, color, data, restoration as skrest
from skimage.transform import radon, resize
from skimage.restoration import denoise_tv_chambolle, denoise_wavelet
from skimage.metrics import peak_signal_noise_ratio as sk_psnr
from skimage.metrics import structural_similarity as sk_ssim
import pandas as pd

# Optional BM3D denoising for superior performance
try:
    from bm3d import bm3d
    HAS_BM3D = True
    print("✅ BM3D loaded - using advanced denoising")
except ImportError:
    HAS_BM3D = False
    print("⚠️ BM3D not available - using wavelet denoising fallback")

print("All libraries loaded successfully")

# =============================================================================
# Cell 2: Comprehensive Configuration with Detailed Parameters
# =============================================================================

# Output directory for results
OUT_DIR = "restoration_outputs"
os.makedirs(OUT_DIR, exist_ok=True)

# Dataset configuration - UPDATE THESE PATHS FOR YOUR DATASET
BLUR_DIR = "motion_blur_dataset_unique/blurred"    # Path to blurred images
GT_DIR = "motion_blur_dataset_unique/ground_truth" # Path to ground truth images

# =============================================================================
# CORE ALGORITHM PARAMETERS - TUNE THESE FOR OPTIMAL PERFORMANCE
# =============================================================================
PARAMS = {
    # Denoising parameters
    'NOISE_SIGMA': 12.0,        # Estimated noise standard deviation
    # Higher values = more aggressive denoising but may lose details
    
    # Wiener deconvolution parameters  
    'WIENER_BAL': 0.01,         # Base regularization parameter for Wiener filter
    # Balances noise amplification vs deblurring strength
    
    # Richardson-Lucy deconvolution parameters
    'RL_ITERS': 100,            # Base number of RL iterations
    'TV_INTERVAL': 6,           # Apply TV regularization every N iterations
    'TV_WEIGHT': 0.008,         # Total Variation regularization strength
    # TV regularization reduces ringing artifacts but may oversmooth textures
    
    # Multiscale processing
    'PYR_LEVELS': 3,            # Number of pyramid levels for multiscale RL
    # More levels handle larger blurs but increase computation time
    
    # PSF estimation and selection
    'MIN_PSF_LEN': 1.5,         # Minimum PSF length to trigger RL deconvolution
    'BORDERLINE_PSF_LEN': 3.0,  # PSF length where RL is conditionally applied
    'FORCE_RL_ON_BORDERLINE': True,  # Whether to force RL for borderline cases
    'MAX_PSF_LEN': 80,          # Maximum allowed PSF length
    
    # Post-processing
    'UNSHARP_AMOUNT': 0.6,      # Sharpening strength (0-1)
    'UNSHARP_SIGMA': 1.0,       # Sharpening radius (pixels)
}

# Display and processing limits
MAX_SAMPLES = 20  # Process all 20 images
VISUALIZE_EVERY = 2  # Show detailed visualization for every Nth sample

random.seed(42)
np.random.seed(42)

print("Configuration loaded with optimized parameters")

# =============================================================================
# Cell 3: Core Image Processing Utilities with Detailed Explanations
# =============================================================================

def fft_conv(img, kernel):
    """
    Fast convolution using FFT for computational efficiency.
    
    Args:
        img: Input image (single or multi-channel)
        kernel: Convolution kernel
        
    Returns:
        Convolved image with same dimensions as input
    """
    if img.ndim == 3:
        # Process each channel separately for color images
        out = np.zeros_like(img)
        for c in range(img.shape[2]):
            out[..., c] = fftconvolve(img[..., c], kernel, mode='same')
        return out
    else:
        # Single channel image
        return fftconvolve(img, kernel, mode='same')


def motion_blur_psf(length: float, angle_deg: float) -> np.ndarray:
    """
    Generate motion blur Point Spread Function (PSF).
    
    The PSF represents how a single point source gets blurred by motion.
    This is crucial for deconvolution-based deblurring.
    
    Args:
        length: Blur length in pixels
        angle_deg: Blur direction in degrees (0° = horizontal right)
        
    Returns:
        2D numpy array representing the motion blur PSF
    """
    length = max(1.0, float(length))
    # Ensure odd-sized kernel for symmetry
    size = max(3, int(math.ceil(length)) | 1)
    psf = np.zeros((size, size), dtype=np.float32)
    center = size // 2
    theta = math.radians(angle_deg)
    
    # Create line of ones along the motion direction
    x_coords = np.linspace(-length/2.0, length/2.0, size)
    
    for x in x_coords:
        xi = int(round(center + x * math.cos(theta)))
        yi = int(round(center + x * math.sin(theta)))
        if 0 <= xi < size and 0 <= yi < size:
            psf[yi, xi] += 1.0
    
    # Normalize PSF to sum to 1 (energy conservation)
    psf_sum = psf.sum()
    if psf_sum == 0:
        psf[center, center] = 1.0  # Fallback: no blur
    else:
        psf /= psf_sum
        
    return psf


def circular_mask(h, w, dtype=np.float32):
    """
    Create circular mask to reduce boundary artifacts in frequency domain processing.
    
    Boundary effects can cause artifacts in FFT-based processing.
    This mask smoothly attenuates image edges.
    
    Args:
        h, w: Mask dimensions
        dtype: Data type for mask
        
    Returns:
        Circular mask with 1.0 in center, 0.0 at edges
    """
    Y, X = np.ogrid[:h, :w]
    cy, cx = h/2.0, w/2.0
    r = min(h, w)/2.0
    mask = ((Y-cy)**2 + (X-cx)**2) <= (r**2)
    return mask.astype(dtype)


def read_rgb(path: str):
    """
    Read image as normalized RGB float array.
    
    Args:
        path: Path to image file
        
    Returns:
        Image as float32 array in range [0, 1]
        
    Raises:
        FileNotFoundError: If image cannot be loaded
    """
    img = cv2.imread(path)
    if img is None:
        raise FileNotFoundError(f"Cannot read image: {path}")
    # Convert BGR (OpenCV default) to RGB
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img.astype('float32') / 255.0


def save_img(path: str, img: np.ndarray):
    """
    Save image with proper formatting and color space.
    
    Args:
        path: Output file path
        img: Image array (float [0,1] or uint8 [0,255])
    """
    if img.dtype != np.uint8:
        u8 = np.clip(img * 255.0, 0, 255).astype('uint8')
    else:
        u8 = img
        
    if u8.ndim == 3:
        # Convert RGB to BGR for OpenCV saving
        cv2.imwrite(path, u8[:, :, ::-1])
    else:
        cv2.imwrite(path, u8)

# =============================================================================
# Cell 4: Advanced Denoising with Adaptive Strategies
# =============================================================================

def denoise_luminance(img_rgb: np.ndarray, sigma: float, use_bm3d: bool = True):
    """
    Advanced denoising applied only to luminance channel.
    
    Working in YCbCr color space allows us to denoise only the luminance (Y)
    while preserving color information in CbCr channels.
    
    Args:
        img_rgb: Input RGB image
        sigma: Estimated noise standard deviation
        use_bm3d: Whether to use BM3D if available
        
    Returns:
        denoised_rgb: Denoised RGB image
        denoised_y: Denoised luminance channel (for further processing)
    """
    # Convert to YCbCr color space
    img_u8 = (img_rgb * 255).astype('uint8')
    ycrcb = cv2.cvtColor(img_u8, cv2.COLOR_RGB2YCrCb).astype('float32') / 255.0
    y = ycrcb[..., 0]  # Luminance channel
    
    # Use BM3D for superior denoising if available
    if HAS_BM3D and use_bm3d:
        try:
            # BM3D is one of the best denoising algorithms for Gaussian noise
            den_y = bm3d(y, sigma_psd=sigma/255.0)
            den_y = np.clip(den_y, 0, 1)
        except Exception as e:
            print(f"BM3D failed, using wavelet fallback: {e}")
            # Wavelet denoising fallback
            den_y = denoise_wavelet(y, sigma=sigma/255.0, convert2y=False, 
                                  method='VisuShrink', mode='soft')
            den_y = denoise_tv_chambolle(den_y, weight=0.01)
    else:
        # Wavelet + TV denoising combination
        den_y = denoise_wavelet(y, sigma=sigma/255.0, convert2y=False, 
                              method='VisuShrink', mode='soft')
        den_y = denoise_tv_chambolle(den_y, weight=0.01)
    
    # Replace luminance channel and convert back to RGB
    ycrcb[..., 0] = den_y
    den_rgb = cv2.cvtColor((ycrcb * 255).astype('uint8'), cv2.COLOR_YCrCb2RGB)
    return den_rgb.astype('float32') / 255.0, den_y


def estimate_snr(y_channel: np.ndarray):
    """
    Estimate Signal-to-Noise Ratio using robust statistics.
    
    Uses Median Absolute Deviation (MAD) for robust noise estimation
    that's less sensitive to outliers than standard deviation.
    
    Args:
        y_channel: Luminance channel image
        
    Returns:
        Estimated SNR value
    """
    med = np.median(y_channel)
    mad = np.median(np.abs(y_channel - med)) + 1e-9
    # MAD to standard deviation conversion factor for normal distribution
    noise_std_est = 1.4826 * mad
    sig_var = np.var(y_channel)
    noise_var = noise_std_est**2
    snr = sig_var / (noise_var + 1e-12)
    return max(0.01, float(snr))


def adaptive_wiener_balance(y_channel: np.ndarray, base=0.01):
    """
    Adapt Wiener regularization parameter based on estimated SNR.
    
    Higher SNR images can tolerate more aggressive deblurring,
    while noisy images need more regularization.
    
    Args:
        y_channel: Luminance channel
        base: Base regularization parameter
        
    Returns:
        Adaptive regularization parameter
    """
    snr = estimate_snr(y_channel)
    # Inverse relationship: higher SNR → lower regularization
    bal = base * (1.0 / (1.0 + 0.1 * snr))
    return float(np.clip(bal, 1e-5, 0.2))

# =============================================================================
# Cell 5: Robust PSF Estimation Using Multiple Techniques
# =============================================================================

def estimate_motion_psf_robust(image_gray: np.ndarray, max_len=120, show=False):
    """
    Robust PSF estimation combining Radon transform and cepstrum analysis.
    
    Uses two complementary techniques:
    1. Radon transform for blur angle estimation
    2. Cepstrum analysis for blur length estimation
    
    Args:
        image_gray: Input grayscale image
        max_len: Maximum allowed blur length
        show: Whether to display intermediate results
        
    Returns:
        psf: Estimated point spread function
        length: Estimated blur length
        angle: Estimated blur angle in degrees
    """
    try:
        # Preprocess image
        img = image_gray.astype(np.float32).copy()
        if img.max() > 1.0 or img.min() < 0.0:
            img = (img - img.min()) / max(1e-9, img.max() - img.min())
        
        h, w = img.shape
        # Apply circular mask to reduce boundary effects
        mask = circular_mask(h, w)
        img_masked = img * mask
        
        # =====================================================================
        # STEP 1: Angle estimation using Radon transform
        # =====================================================================
        # The Radon transform computes line integrals at various angles
        # Motion blur direction has maximum variance in Radon space
        theta = np.linspace(0., 180., 90, endpoint=False)
        R = radon(img_masked, theta=theta, circle=True)
        # Find angle with maximum variance (most prominent direction)
        angle = float(theta[int(np.argmax(R.var(axis=0)))])
        
        # =====================================================================
        # STEP 2: Length estimation using cepstrum analysis
        # =====================================================================
        # Rotate image to align blur with horizontal for easier analysis
        rot_img = ndimage.rotate(img_masked, -angle, reshape=False, mode='reflect')
        
        # Cepstrum = inverse FFT of log magnitude spectrum
        # Peaks in cepstrum correspond to periodic patterns (like motion blur)
        mag_spectrum = np.abs(np.fft.fft2(rot_img)) + 1e-8
        cepstrum = np.real(np.fft.ifft2(np.log(mag_spectrum)))
        
        # Analyze center row of cepstrum for blur length
        center_row = cepstrum[cepstrum.shape[0]//2, :]
        peaks, _ = find_peaks(np.abs(center_row), distance=2, 
                            height=(np.mean(np.abs(center_row)) * 1.05))
        
        if len(peaks) == 0:
            # No clear peaks found, use conservative estimate
            length = min(max_len, 6)
        else:
            # Use distance from center to first peak as blur length estimate
            center = len(center_row)//2
            peak = peaks[np.argmin(np.abs(peaks - center))]
            length = abs(peak - center)
        
        # Constrain length to reasonable bounds
        length = max(1.0, min(length, max_len))
        psf = motion_blur_psf(length, angle)
        
        if show:
            # Visualize estimated PSF
            plt.figure(figsize=(5, 4))
            plt.imshow(psf, cmap='viridis')
            plt.title(f"Estimated PSF: Length={length:.1f}px, Angle={angle:.1f}°")
            plt.colorbar()
            plt.axis('off')
            plt.tight_layout()
            plt.show()
        
        return psf, length, angle
        
    except Exception as e:
        warnings.warn(f"PSF estimation failed: {e}, using default PSF")
        # Fallback: identity PSF (no blur)
        return motion_blur_psf(1, 0), 1.0, 0.0

# =============================================================================
# Cell 6: Multiscale Richardson-Lucy Deconvolution with TV Regularization
# =============================================================================

def rl_tv_deconvolution(y_obs, psf, init=None, max_iters=60, tv_interval=6, tv_weight=0.01):
    """
    Richardson-Lucy deconvolution with Total Variation regularization.
    
    RL deconvolution is iterative and can handle noise better than Wiener,
    but may produce ringing artifacts. TV regularization reduces these artifacts
    by encouraging piecewise smooth solutions.
    
    Args:
        y_obs: Observed blurred image
        psf: Point spread function
        init: Initial guess (defaults to observed image)
        max_iters: Maximum iterations
        tv_interval: Apply TV regularization every N iterations
        tv_weight: TV regularization strength
        
    Returns:
        deconvolved: Restored image
    """
    if init is None:
        current = y_obs.copy()
    else:
        current = init.copy()
    
    # Precompute flipped PSF for correlation
    psf_flipped = psf[::-1, ::-1]
    
    for iteration in range(max_iters):
        # Richardson-Lucy iteration:
        # current = current * (y_obs / (current ⊗ psf)) ⊗ psf_flipped
        conv_current = fft_conv(current, psf)
        conv_current = np.clip(conv_current, 1e-12, 1.0)  # Avoid division by zero
        relative_blur = y_obs / conv_current
        error_est = fft_conv(relative_blur, psf_flipped)
        current = current * error_est
        current = np.clip(current, 0, 1)
        
        # Apply TV regularization at specified intervals
        if (iteration + 1) % tv_interval == 0:
            current = denoise_tv_chambolle(current, weight=tv_weight)
    
    return current


def analyze_texture_simple(img_rgb: np.ndarray):
    """
    Simple texture analysis using gradient magnitude.
    
    Used to adapt algorithm parameters based on image content:
    - High texture: Use lighter TV regularization to preserve details
    - Low texture: Use stronger TV to suppress artifacts
    
    Args:
        img_rgb: Input RGB image
        
    Returns:
        Dictionary with texture analysis results and recommendations
    """
    gray = cv2.cvtColor((img_rgb * 255).astype('uint8'), cv2.COLOR_RGB2GRAY)
    gray = gray.astype('float32') / 255.0
    
    # Compute gradient magnitude using Sobel filters
    grad_x = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
    grad_mag = np.sqrt(grad_x**2 + grad_y**2)
    
    # Texture energy = average gradient magnitude
    texture_energy = np.mean(grad_mag)
    
    # Adaptive parameter recommendations
    if texture_energy > 0.1:
        # High texture: preserve details with lighter regularization
        tv_weight = 0.004
        sharpening_factor = 0.7  # Less sharpening to avoid artifacts
    elif texture_energy < 0.03:
        # Smooth regions: stronger regularization to suppress artifacts
        tv_weight = 0.02
        sharpening_factor = 1.3  # More sharpening to enhance edges
    else:
        # Moderate texture: balanced approach
        tv_weight = 0.01
        sharpening_factor = 1.0
    
    return {
        'texture_energy': texture_energy,
        'recommended_tv_weight': tv_weight,
        'sharpening_factor': sharpening_factor
    }

# =============================================================================
# Cell 7: Complete Restoration Pipeline
# =============================================================================

def restore_image_adaptive(img_rgb: np.ndarray, params: dict, show_progress: bool = True):
    """
    Complete adaptive restoration pipeline with intelligent parameter selection.
    
    Pipeline stages:
    1. Texture analysis for parameter adaptation
    2. Luminance denoising
    3. PSF estimation
    4. Wiener deconvolution
    5. Conditional RL+TV refinement
    6. Adaptive sharpening
    
    Args:
        img_rgb: Input blurred RGB image
        params: Algorithm parameters dictionary
        show_progress: Whether to print progress information
        
    Returns:
        Dictionary containing all intermediate and final results
    """
    results = {'input': img_rgb.copy()}
    
    if show_progress:
        print("🔍 Analyzing image texture...")
    
    # Step 1: Texture analysis for adaptive parameter selection
    texture_info = analyze_texture_simple(img_rgb)
    adaptive_tv = texture_info['recommended_tv_weight']
    sharpening_factor = texture_info['sharpening_factor']
    
    if show_progress:
        print(f"   Texture energy: {texture_info['texture_energy']:.3f}")
        print(f"   Adaptive TV weight: {adaptive_tv:.4f}")
    
    # Step 2: Luminance-channel denoising
    if show_progress:
        print("🎨 Applying adaptive denoising...")
    
    denoised, denoised_y = denoise_luminance(img_rgb, params['NOISE_SIGMA'])
    results['denoised'] = denoised
    
    # Step 3: PSF estimation
    if show_progress:
        print("📐 Estimating motion blur PSF...")
    
    psf, psf_len, psf_ang = estimate_motion_psf_robust(
        denoised_y, 
        max_len=params.get('MAX_PSF_LEN', 80)
    )
    results['psf'] = psf
    results['psf_len'] = psf_len
    results['psf_ang'] = psf_ang
    
    if show_progress:
        print(f"   Estimated PSF: length={psf_len:.1f}px, angle={psf_ang:.1f}°")
    
    # Step 4: Decision logic - whether to use RL deconvolution
    center_profile = psf[psf.shape[0]//2, :]
    use_rl = (np.count_nonzero(center_profile > 1e-6) > 3 and 
              psf_len >= params['MIN_PSF_LEN'])
    
    # Step 5: Wiener deconvolution (always applied)
    if show_progress:
        print("🔄 Applying Wiener deconvolution...")
    
    # Convert to YCbCr for luminance processing
    ycrcb = cv2.cvtColor((denoised * 255).astype('uint8'), cv2.COLOR_RGB2YCrCb)
    ycrcb = ycrcb.astype('float32') / 255.0
    y_channel = ycrcb[..., 0]
    
    # Adaptive Wiener balance based on SNR
    wiener_balance = adaptive_wiener_balance(y_channel, params['WIENER_BAL'])
    wiener_y = skrest.wiener(y_channel, psf, wiener_balance)
    wiener_y = np.clip(wiener_y, 0, 1)
    
    # Convert back to RGB
    ycrcb[..., 0] = wiener_y
    wiener_rgb = cv2.cvtColor((ycrcb * 255).astype('uint8'), cv2.COLOR_YCrCb2RGB)
    wiener_rgb = wiener_rgb.astype('float32') / 255.0
    results['wiener'] = wiener_rgb
    
    # Step 6: Conditional RL+TV refinement
    if use_rl:
        if show_progress:
            print("⚡ Applying RL+TV deconvolution...")
        
        # Adaptive iterations based on blur severity
        adaptive_iters = params['RL_ITERS']
        if psf_len > 15:
            adaptive_iters = min(200, int(adaptive_iters * 1.5))  # More iterations for severe blur
        elif psf_len < 3:
            adaptive_iters = max(40, int(adaptive_iters * 0.7))   # Fewer iterations for mild blur
        
        # Apply RL+TV deconvolution
        rl_y = rl_tv_deconvolution(
            y_channel, psf, init=wiener_y,
            max_iters=adaptive_iters,
            tv_interval=params['TV_INTERVAL'],
            tv_weight=adaptive_tv
        )
        
        # Convert back to RGB
        ycrcb[..., 0] = rl_y
        deconvolved_rgb = cv2.cvtColor((ycrcb * 255).astype('uint8'), cv2.COLOR_YCrCb2RGB)
        deconvolved_rgb = deconvolved_rgb.astype('float32') / 255.0
        base_for_sharpening = deconvolved_rgb
        results['used_rl'] = True
        results['adaptive_iters'] = adaptive_iters
        
        if show_progress:
            print(f"   Applied {adaptive_iters} RL iterations with TV regularization")
    else:
        if show_progress:
            print("⏭️  Skipping RL - using Wiener result")
        base_for_sharpening = wiener_rgb
        results['used_rl'] = False
    
    # Step 7: Adaptive sharpening
    if show_progress:
        print("✨ Applying adaptive sharpening...")
    
    adaptive_sharpening = params['UNSHARP_AMOUNT'] * sharpening_factor
    # Simple unsharp masking
    blurred = ndimage.gaussian_filter(base_for_sharpening, sigma=(params['UNSHARP_SIGMA'], 
                                                                 params['UNSHARP_SIGMA'], 0))
    final = np.clip(base_for_sharpening + adaptive_sharpening * (base_for_sharpening - blurred), 0, 1)
    results['final'] = final
    results['adaptive_sharpening'] = adaptive_sharpening
    
    if show_progress:
        print("✅ Restoration complete!")
    
    return results

# =============================================================================
# Cell 8: Enhanced Visualization System
# =============================================================================

class ComprehensiveVisualizer:
    """
    Professional visualization system for restoration results.
    
    Provides multiple visualization types:
    - Pipeline stages overview
    - Quality metrics comparison
    - PSF analysis
    - Performance summaries
    """
    
    def __init__(self):
        self.sample_count = 0
    
    def plot_pipeline_stages(self, results, metrics=None, sample_name="Sample"):
        """
        Visualize all stages of the restoration pipeline.
        
        Args:
            results: Dictionary containing pipeline results
            metrics: Quality metrics dictionary
            sample_name: Name for plot title
        """
        stages = {
            'Input': results.get('input'),
            'Denoised': results.get('denoised'),
            'Wiener Deconv': results.get('wiener'),
            'Final': results.get('final')
        }
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        axes = axes.flatten()
        
        for idx, (stage_name, img) in enumerate(stages.items()):
            if img is not None:
                axes[idx].imshow(np.clip(img, 0, 1))
                axes[idx].set_title(stage_name, fontweight='bold', fontsize=12)
                axes[idx].axis('off')
        
        # Add metrics if available
        if metrics:
            metrics_text = (
                f"PSNR: {metrics['PSNR_input']:.2f} → {metrics['PSNR_final']:.2f} dB\n"
                f"SSIM: {metrics['SSIM_input']:.4f} → {metrics['SSIM_final']:.4f}\n"
                f"PSF: {results.get('psf_len', 0):.1f}px, {results.get('psf_ang', 0):.1f}°"
            )
            fig.text(0.02, 0.02, metrics_text, fontsize=10,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
        
        plt.suptitle(f"Restoration Pipeline - {sample_name}", fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.show()
    
    def plot_psf_analysis(self, psf, psf_len, psf_ang):
        """
        Detailed visualization of the estimated PSF.
        
        Args:
            psf: Estimated point spread function
            psf_len: Estimated blur length
            psf_ang: Estimated blur angle
        """
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
        
        # PSF heatmap
        im1 = ax1.imshow(psf, cmap='viridis', interpolation='nearest')
        ax1.set_title(f'Estimated PSF\nLength: {psf_len:.1f}px, Angle: {psf_ang:.1f}°', 
                     fontweight='bold')
        ax1.axis('off')
        plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)
        
        # Center profile
        center_row = psf[psf.shape[0]//2, :]
        ax2.plot(center_row, 'b-', linewidth=2, marker='o', markersize=3)
        ax2.fill_between(range(len(center_row)), center_row, alpha=0.3)
        ax2.set_title('Horizontal Center Profile')
        ax2.set_xlabel('Position')
        ax2.set_ylabel('Intensity')
        ax2.grid(True, alpha=0.3)
        
        # 3D surface plot
        x = np.arange(psf.shape[1])
        y = np.arange(psf.shape[0])
        X, Y = np.meshgrid(x, y)
        contour = ax3.contourf(X, Y, psf, levels=20, cmap='viridis')
        ax3.set_title('PSF Contour Plot')
        ax3.axis('off')
        plt.colorbar(contour, ax=ax3, fraction=0.046, pad=0.04)
        
        # Statistics
        ax4.axis('off')
        stats_text = (
            f"PSF Statistics:\n"
            f"• Size: {psf.shape}\n"
            f"• Sum: {psf.sum():.4f}\n"
            f"• Max: {psf.max():.4f}\n"
            f"• Min: {psf.min():.4f}\n"
            f"• Non-zero pixels: {np.count_nonzero(psf > 1e-6)}"
        )
        ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=11,
                verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
        
        plt.tight_layout()
        plt.show()
    
    def plot_quality_comparison(self, input_img, restored_img, gt_img, metrics, sample_name):
        """
        Side-by-side comparison of input, restored, and ground truth.
        
        Args:
            input_img: Blurred input image
            restored_img: Restored image
            gt_img: Ground truth image
            metrics: Quality metrics dictionary
            sample_name: Sample identifier
        """
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # Input image
        axes[0].imshow(np.clip(input_img, 0, 1))
        axes[0].set_title(f'Input\nPSNR: {metrics["PSNR_input"]:.2f} dB\nSSIM: {metrics["SSIM_input"]:.4f}')
        axes[0].axis('off')
        
        # Restored image
        axes[1].imshow(np.clip(restored_img, 0, 1))
        axes[1].set_title(f'Restored\nPSNR: {metrics["PSNR_final"]:.2f} dB\nSSIM: {metrics["SSIM_final"]:.4f}')
        axes[1].axis('off')
        
        # Ground truth
        axes[2].imshow(np.clip(gt_img, 0, 1))
        axes[2].set_title('Ground Truth')
        axes[2].axis('off')
        
        # Improvement information
        psnr_imp = metrics['PSNR_improvement']
        ssim_imp = metrics['SSIM_improvement']
        
        fig.text(0.5, 0.02, 
                f"Improvement: PSNR {psnr_imp:+.2f} dB | SSIM {ssim_imp:+.4f}",
                ha='center', fontsize=12, 
                bbox=dict(boxstyle="round,pad=0.3", 
                         facecolor="lightgreen" if psnr_imp > 0 else "lightcoral"))
        
        plt.suptitle(f"Quality Comparison - {sample_name}", fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.show()
    
    def plot_performance_summary(self, df_results):
        """
        Comprehensive performance summary across all samples.
        
        Args:
            df_results: DataFrame containing results for all samples
        """
        if len(df_results) == 0:
            print("No results to visualize")
            return
            
        # Filter successful results
        successful = df_results[df_results['PSNR_improvement'].notna()]
        if len(successful) == 0:
            print("No successful results with metrics")
            return
            
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # Plot 1: PSNR improvements
        samples = successful['sample']
        psnr_improvements = successful['PSNR_improvement']
        
        colors = ['green' if x > 0 else 'red' for x in psnr_improvements]
        bars = ax1.bar(range(len(samples)), psnr_improvements, color=colors, alpha=0.7)
        ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)
        ax1.set_xlabel('Sample')
        ax1.set_ylabel('PSNR Improvement (dB)')
        ax1.set_title('PSNR Improvements by Sample', fontweight='bold')
        ax1.set_xticks(range(len(samples)))
        ax1.set_xticklabels(samples, rotation=45)
        ax1.grid(True, alpha=0.3)
        
        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:+.2f}', ha='center', va='bottom' if height >= 0 else 'top', fontsize=9)
        
        # Plot 2: SSIM improvements
        ssim_improvements = successful['SSIM_improvement']
        colors = ['green' if x > 0 else 'red' for x in ssim_improvements]
        bars = ax2.bar(range(len(samples)), ssim_improvements, color=colors, alpha=0.7)
        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
        ax2.set_xlabel('Sample')
        ax2.set_ylabel('SSIM Improvement')
        ax2.set_title('SSIM Improvements by Sample', fontweight='bold')
        ax2.set_xticks(range(len(samples)))
        ax2.set_xticklabels(samples, rotation=45)
        ax2.grid(True, alpha=0.3)
        
        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:+.4f}', ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)
        
        # Plot 3: Scatter plot of improvements
        ax3.scatter(psnr_improvements, ssim_improvements, alpha=0.7, s=100)
        ax3.axvline(0, color='red', linestyle='--', alpha=0.5)
        ax3.axhline(0, color='red', linestyle='--', alpha=0.5)
        ax3.set_xlabel('PSNR Improvement (dB)')
        ax3.set_ylabel('SSIM Improvement')
        ax3.set_title('Improvement Correlation', fontweight='bold')
        ax3.grid(True, alpha=0.3)
        
        # Annotate points with sample names
        for i, (sample, px, sx) in enumerate(zip(samples, psnr_improvements, ssim_improvements)):
            ax3.annotate(sample, (px, sx), xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        # Plot 4: Summary statistics
        ax4.axis('off')
        avg_psnr_imp = np.mean(psnr_improvements)
        avg_ssim_imp = np.mean(ssim_improvements)
        psnr_improved = sum(psnr_improvements > 0)
        ssim_improved = sum(ssim_improvements > 0)
        total_samples = len(successful)
        
        summary_text = (
            f"PERFORMANCE SUMMARY\n\n"
            f"PSNR Results:\n"
            f"• Average Improvement: {avg_psnr_imp:+.2f} dB\n"
            f"• Best Improvement: {max(psnr_improvements):+.2f} dB\n"
            f"• Worst Improvement: {min(psnr_improvements):+.2f} dB\n"
            f"• Improved Samples: {psnr_improved}/{total_samples}\n\n"
            f"SSIM Results:\n"
            f"• Average Improvement: {avg_ssim_imp:+.4f}\n"
            f"• Best Improvement: {max(ssim_improvements):+.4f}\n"
            f"• Worst Improvement: {min(ssim_improvements):+.4f}\n"
            f"• Improved Samples: {ssim_improved}/{total_samples}\n\n"
            f"Success Rate: {total_samples}/{len(df_results)} samples"
        )
        
        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=11,
                verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"))
        
        plt.tight_layout()
        plt.show()

# Create global visualizer instance
viz = ComprehensiveVisualizer()

# =============================================================================
# Cell 9: Dataset Management and Quality Metrics
# =============================================================================

def load_complete_dataset():
    """
    Load the complete motion blur dataset with all 20 images.
    
    Returns:
        List of tuples: (blurred_image, ground_truth_image, filename)
    """
    samples = []
    
    if not os.path.exists(BLUR_DIR):
        print(f"❌ Error: Blur directory not found: {BLUR_DIR}")
        print("Please check the BLUR_DIR path in the configuration section")
        return []
    
    # Get all image files
    image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif')
    blur_files = sorted([f for f in os.listdir(BLUR_DIR) 
                        if f.lower().endswith(image_extensions)])
    
    print(f"📁 Loading dataset from {BLUR_DIR}")
    print(f"📊 Found {len(blur_files)} blurred images")
    
    if not blur_files:
        print("❌ No image files found in blur directory")
        return []
    
    gt_available = 0
    for blur_file in blur_files:
        try:
            blur_path = os.path.join(BLUR_DIR, blur_file)
            blur_img = read_rgb(blur_path)
            
            # Try to find corresponding ground truth
            gt_img = None
            if GT_DIR and os.path.exists(GT_DIR):
                # Try different naming conventions
                possible_gt_names = [
                    blur_file.replace('_blur.', '_gt.'),
                    blur_file.replace('blur', 'sharp'),
                    blur_file.replace('blurred', 'sharp'),
                    blur_file.replace('input', 'target'),
                    'gt_' + blur_file,
                    blur_file  # Same name
                ]
                
                for gt_name in possible_gt_names:
                    gt_path = os.path.join(GT_DIR, gt_name)
                    if os.path.exists(gt_path):
                        gt_img = read_rgb(gt_path)
                        gt_available += 1
                        break
            
            samples.append((blur_img, gt_img, blur_file))
            print(f"✅ Loaded: {blur_file}" + (" + GT" if gt_img is not None else ""))
            
        except Exception as e:
            print(f"❌ Error loading {blur_file}: {e}")
    
    print(f"\n📋 Dataset Summary:")
    print(f"   Total samples: {len(samples)}")
    print(f"   With ground truth: {gt_available}")
    print(f"   Without ground truth: {len(samples) - gt_available}")
    
    return samples


def compute_comprehensive_metrics(gt_rgb: np.ndarray, input_rgb: np.ndarray, restored_rgb: np.ndarray):
    """
    Compute comprehensive quality metrics between images.
    
    Args:
        gt_rgb: Ground truth image
        input_rgb: Blurred input image  
        restored_rgb: Restored image
        
    Returns:
        Dictionary containing PSNR and SSIM metrics
    """
    # Ensure all images have same dimensions
    if input_rgb.shape[:2] != gt_rgb.shape[:2]:
        input_rgb = cv2.resize(input_rgb, (gt_rgb.shape[1], gt_rgb.shape[0]))
    if restored_rgb.shape[:2] != gt_rgb.shape[:2]:
        restored_rgb = cv2.resize(restored_rgb, (gt_rgb.shape[1], gt_rgb.shape[0]))
    
    def to_y_channel(img):
        """Convert RGB image to luminance (Y) channel for fair comparison."""
        ycrcb = cv2.cvtColor((img * 255).astype('uint8'), cv2.COLOR_RGB2YCrCb)
        return ycrcb[..., 0].astype('float32') / 255.0
    
    # Convert to Y channel
    gt_y = to_y_channel(gt_rgb)
    inp_y = to_y_channel(input_rgb)
    res_y = to_y_channel(restored_rgb)
    
    # Compute PSNR
    psnr_input = sk_psnr(gt_y, inp_y, data_range=1.0)
    psnr_restored = sk_psnr(gt_y, res_y, data_range=1.0)
    
    # Compute SSIM with adaptive window size
    min_dim = min(gt_y.shape[0], gt_y.shape[1])
    win_size = min(7, min_dim) if min_dim % 2 == 1 else min(7, min_dim - 1)
    win_size = max(3, win_size)
    
    ssim_input = sk_ssim(gt_y, inp_y, data_range=1.0, win_size=win_size)
    ssim_restored = sk_ssim(gt_y, res_y, data_range=1.0, win_size=win_size)
    
    return {
        'PSNR_input': psnr_input,
        'PSNR_final': psnr_restored,
        'SSIM_input': ssim_input,
        'SSIM_final': ssim_restored,
        'PSNR_improvement': psnr_restored - psnr_input,
        'SSIM_improvement': ssim_restored - ssim_input
    }

# =============================================================================
# Cell 10: Main Execution Pipeline
# =============================================================================

def run_comprehensive_evaluation():
    """
    Run complete evaluation on all dataset images.
    
    Returns:
        DataFrame with detailed results for all samples
    """
    print("=" * 70)
    print("🚀 STARTING COMPREHENSIVE MOTION DEBLURRING EVALUATION")
    print("=" * 70)
    
    # Load complete dataset
    print("\n📥 Loading dataset...")
    samples = load_complete_dataset()
    
    if not samples:
        print("❌ No samples loaded. Exiting.")
        return pd.DataFrame()
    
    print(f"\n✅ Successfully loaded {len(samples)} samples")
    
    # Process all samples
    all_results = []
    all_metrics = []
    
    print(f"\n🔬 Processing {len(samples)} images...")
    print("=" * 50)
    
    for i, (blur_img, gt_img, filename) in enumerate(samples):
        sample_name = f"sample_{i+1:02d}"
        print(f"\n🎯 Processing {sample_name}: {filename}")
        print("-" * 40)
        
        try:
            # Apply adaptive restoration
            restoration_results = restore_image_adaptive(blur_img, PARAMS, show_progress=True)
            final_img = restoration_results['final']
            
            # Compute metrics if ground truth available
            metrics = None
            if gt_img is not None:
                metrics = compute_comprehensive_metrics(gt_img, blur_img, final_img)
                all_metrics.append(metrics)
                
                print(f"📊 Quality Metrics:")
                print(f"   PSNR: {metrics['PSNR_input']:.2f} → {metrics['PSNR_final']:.2f} dB "
                      f"(Δ{metrics['PSNR_improvement']:+.2f})")
                print(f"   SSIM: {metrics['SSIM_input']:.4f} → {metrics['SSIM_final']:.4f} "
                      f"(Δ{metrics['SSIM_improvement']:+.4f})")
            
            # Enhanced visualization for selected samples
            if i % VISUALIZE_EVERY == 0:  # Show every Nth sample
                if gt_img is not None and metrics is not None:
                    viz.plot_quality_comparison(blur_img, final_img, gt_img, metrics, sample_name)
                viz.plot_pipeline_stages(restoration_results, metrics, sample_name)
                
                # Show PSF analysis for first few samples
                if i < 3:
                    viz.plot_psf_analysis(
                        restoration_results['psf'],
                        restoration_results['psf_len'],
                        restoration_results['psf_ang']
                    )
            
            # Collect results
            result_row = {
                'sample': sample_name,
                'filename': filename,
                'psf_length': restoration_results.get('psf_len', 0),
                'psf_angle': restoration_results.get('psf_ang', 0),
                'used_rl': restoration_results.get('used_rl', False),
                'adaptive_iters': restoration_results.get('adaptive_iters', 0),
            }
            
            if metrics is not None:
                result_row.update(metrics)
            
            all_results.append(result_row)
            
            # Save output images
            base_path = os.path.join(OUT_DIR, sample_name)
            save_img(f"{base_path}_input.png", blur_img)
            save_img(f"{base_path}_final.png", final_img)
            if gt_img is not None:
                save_img(f"{base_path}_gt.png", gt_img)
            
            print(f"💾 Saved results for {sample_name}")
            
        except Exception as e:
            print(f"❌ Error processing {sample_name}: {e}")
            all_results.append({
                'sample': sample_name,
                'filename': filename,
                'error': str(e)
            })
    
    # Create results DataFrame
    df_results = pd.DataFrame(all_results)
    
    # Display comprehensive summary
    if all_metrics:
        print("\n" + "=" * 70)
        print("📈 COMPREHENSIVE PERFORMANCE SUMMARY")
        print("=" * 70)
        
        psnr_improvements = [m['PSNR_improvement'] for m in all_metrics]
        ssim_improvements = [m['SSIM_improvement'] for m in all_metrics]
        
        avg_psnr_imp = np.mean(psnr_improvements)
        avg_ssim_imp = np.mean(ssim_improvements)
        psnr_improved = sum(1 for p in psnr_improvements if p > 0)
        ssim_improved = sum(1 for s in ssim_improvements if s > 0)
        total_with_metrics = len(all_metrics)
        
        print(f"\n📊 Overall Results ({total_with_metrics} samples with ground truth):")
        print(f"   Average PSNR Improvement: {avg_psnr_imp:+.2f} dB")
        print(f"   Average SSIM Improvement: {avg_ssim_imp:+.4f}")
        print(f"   Samples with PSNR improvement: {psnr_improved}/{total_with_metrics}")
        print(f"   Samples with SSIM improvement: {ssim_improved}/{total_with_metrics}")
        
        # Show detailed performance visualization
        viz.plot_performance_summary(df_results)
    
    # Save detailed results to CSV
    results_csv = os.path.join(OUT_DIR, "comprehensive_restoration_results.csv")
    df_results.to_csv(results_csv, index=False)
    print(f"\n💾 Detailed results saved to: {results_csv}")
    
    # Final summary
    successful = len([r for r in all_results if 'error' not in r])
    print(f"\n🎉 PIPELINE COMPLETED SUCCESSFULLY!")
    print(f"   Processed: {successful}/{len(samples)} samples successfully")
    print(f"   Output directory: {OUT_DIR}")
    
    return df_results


# =============================================================================
# Cell 11: Main Execution Block
# =============================================================================

if __name__ == "__main__":
    """
    Main execution block - runs the complete evaluation pipeline.
    """
    print("=" * 70)
    print("🏁 MOTION DEBLURRING PIPELINE - EXECUTION START")
    print("=" * 70)
    
    # Run comprehensive evaluation
    start_time = time.time()
    results_df = run_comprehensive_evaluation()
    end_time = time.time()
    
    print(f"\n⏱️  Total execution time: {end_time - start_time:.2f} seconds")
    print("=" * 70)
    
    # Display final results summary
    if not results_df.empty:
        print("\n📋 FINAL RESULTS SUMMARY:")
        print(results_df.to_string(index=False, 
                                columns=['sample', 'filename', 'PSNR_improvement', 'SSIM_improvement']))
    
    print("=" * 70)
    print("🏁 EXECUTION COMPLETE")
    print("=" * 70)
